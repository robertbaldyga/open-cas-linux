#!/bin/bash
#
# Copyright(c) 2012-2022 Intel Corporation
# Copyright(c) 2024 Huawei Technologies
# SPDX-License-Identifier: BSD-3-Clause
#

. $(dirname $3)/conf_framework.sh

# RHEL 7.3
check() {
	cur_name=$(basename $2)
	config_file_path=$1

	if compile_module $cur_name "struct queue_limits q; q.max_write_zeroes_sectors;" "linux/blkdev.h"
	then
		if compile_module $cur_name "struct queue_limits q; q.misaligned;" "linux/blkdev.h"
		then
			if compile_module $cur_name "struct queue_limits q; q.max_write_same_sectors;" "linux/blkdev.h"
			then
				echo $cur_name "1" >> $config_file_path
			else
				echo $cur_name "2" >> $config_file_path
			fi
		else
			echo $cur_name "3" >> $config_file_path
		fi
	elif compile_module $cur_name "struct queue_limits q; q.max_write_same_sectors;" "linux/blkdev.h"
	then
		echo $cur_name "4" >> $config_file_path
	elif compile_module $cur_name "struct queue_limits q; q.limits_aux;" "linux/blkdev.h"
	then
		echo $cur_name "5" >> $config_file_path
	else
		echo $cur_name "X" >> $config_file_path
	fi
}

apply() {
    case "$1" in
    "1")
		add_function "
	static inline void cas_copy_queue_limits(struct request_queue *exp_q,
			struct queue_limits *cache_q_limits, struct request_queue *core_q)
	{
		exp_q->limits = *cache_q_limits;
		exp_q->limits.max_sectors = core_q->limits.max_sectors;
		exp_q->limits.max_hw_sectors = core_q->limits.max_hw_sectors;
		exp_q->limits.max_segments = core_q->limits.max_segments;
		exp_q->limits.max_write_same_sectors = 0;
		exp_q->limits.max_write_zeroes_sectors = 0;
	}"

		add_function "
	static inline void cas_cache_set_no_merges_flag(struct request_queue *cache_q)
	{
	}
	static inline bool cas_queue_limits_is_misaligned(
			struct queue_limits *lim)
	{
		return lim->misaligned;
	}" ;;
    "2")
		add_function "
	static inline void cas_copy_queue_limits(struct request_queue *exp_q,
			struct queue_limits *cache_q_limits, struct request_queue *core_q)
	{
		exp_q->limits = *cache_q_limits;
		exp_q->limits.max_sectors = core_q->limits.max_sectors;
		exp_q->limits.max_hw_sectors = core_q->limits.max_hw_sectors;
		exp_q->limits.max_segments = core_q->limits.max_segments;
		exp_q->limits.max_write_zeroes_sectors = 0;
	}"

		add_function "
	static inline void cas_cache_set_no_merges_flag(struct request_queue *cache_q)
	{
	}
	static inline bool cas_queue_limits_is_misaligned(
			struct queue_limits *lim)
	{
		return lim->misaligned;
	}" ;;
    "3")
		add_function "
	static inline void cas_copy_queue_limits(struct request_queue *exp_q,
			struct queue_limits *cache_q_limits, struct request_queue *core_q)
	{
		exp_q->limits = *cache_q_limits;
		exp_q->limits.max_sectors = core_q->limits.max_sectors;
		exp_q->limits.max_hw_sectors = core_q->limits.max_hw_sectors;
		exp_q->limits.max_segments = core_q->limits.max_segments;
		exp_q->limits.max_write_zeroes_sectors = 0;
	}"

		add_function "
	static inline void cas_cache_set_no_merges_flag(struct request_queue *cache_q)
	{
	}
	static inline bool cas_queue_limits_is_misaligned(
			struct queue_limits *lim)
	{
		return lim->features & BLK_FLAG_MISALIGNED;
	}" ;;
    "4")
		add_function "
	static inline void cas_copy_queue_limits(struct request_queue *exp_q,
			struct queue_limits *cache_q_limits, struct request_queue *core_q)
	{
		exp_q->limits = *cache_q_limits;
		exp_q->limits.max_sectors = core_q->limits.max_sectors;
		exp_q->limits.max_hw_sectors = core_q->limits.max_hw_sectors;
		exp_q->limits.max_segments = core_q->limits.max_segments;
		exp_q->limits.max_write_same_sectors = 0;
	}"

		add_function "
	static inline void cas_cache_set_no_merges_flag(struct request_queue *cache_q)
	{
	}
	static inline bool cas_queue_limits_is_misaligned(
			struct queue_limits *lim)
	{
		return lim->misaligned;
	}" ;;
    "5")
		add_function "
	static inline void cas_copy_queue_limits(struct request_queue *exp_q,
			struct queue_limits *cache_q_limits, struct request_queue *core_q)
	{
		struct queue_limits_aux *l_aux = exp_q->limits.limits_aux;
		exp_q->limits = *cache_q_limits;
		exp_q->limits.limits_aux = l_aux;
		if (exp_q->limits.limits_aux && cache_q_limits->limits_aux)
			*exp_q->limits.limits_aux = *cache_q_limits->limits_aux;
		exp_q->limits.max_sectors = core_q->limits.max_sectors;
		exp_q->limits.max_hw_sectors = core_q->limits.max_hw_sectors;
		exp_q->limits.max_segments = core_q->limits.max_segments;
		exp_q->limits.max_write_same_sectors = 0;
	}"

	 # A workaround for RHEL/CentOS 7.3 bug in kernel.
	 # Merging implementation on blk-mq does not respect virt boundary
	 # restriction and front merges bios with non-zero offsets.
	 # This leads to request with gaps between bios and in consequence
	 # triggers BUG_ON() in nvme driver or silently corrupts data.
	 # To prevent this, disable merging on cache queue if there are
	 # requirements regarding virt boundary (marking bios with REQ_NOMERGE
	 # does not solve this problem).
		add_function "
	static inline void cas_cache_set_no_merges_flag(struct request_queue *cache_q)
	{
		if (queue_virt_boundary(cache_q))
			queue_flag_set(QUEUE_FLAG_NOMERGES, cache_q);
	}
	static inline bool cas_queue_limits_is_misaligned(
			struct queue_limits *lim)
	{
		return lim->misaligned;
	}" ;;


    *)
        exit 1
    esac
}

conf_run $@
